{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo of using PDBrenum to perform mapping of chain IDs in PDB files to UniProt IDs\n",
    "\n",
    "PDBrenum ([GitHub repo](https://github.com/Faezov/PDBrenum) & associated [2021 publication](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0253411)) is used here as the first step to perform mapping of chain identifiers in PDB files to UniProt IDs. PDBrenum uses information form the [SIFTS project database](https://www.ebi.ac.uk/pdbe/docs/sifts/) to take a PDB structure file renumber chains in PDB files to match the UniProt entries. SIFTS stands for 'Structure integration with function, taxonomy and sequence' and is an up-to-date resource for residue-level mapping between UniProt and PDB entries. PDBrenum handles accessing that information as part of its process and makes several files that summarize the information from there. If you wish, you can look at demonstration of PDBrenum [here](demo.ipynb). That is probably not necessary to understand what is going on here as use of the PDBrenum code is fairly straightforward as it handles all the steps for you, and knowing what it does and that it generates as a side product files summarizing appropriate data you can probably understand why it could be useful as part of an endeavor to mapr chain identifiers to UniProt identifiers.\n",
    "\n",
    "Needing to map chain identifiers to UniProt identifiers is apparently a common task as it has come up several times, see [here](https://www.biostars.org/p/9540519/#9540519) which contains a reference to other people seeking this ability. Although other modern solutions were offered there and the OP offered code they put together, it's always good to have options.  My suggestion of using PDBrenum to do the first step saves a lot of coding as really the job is already done. You just need to get the data PDBrenum summaizes as part of its effort back into Python where it can be used further. I assume the developers of PDBrenum will have reason to support the code for sometime as they have published about it. \n",
    "\n",
    "\n",
    "Compare and contrast with process & result from johnnytam100's [pdb2uniprot](https://github.com/johnnytam100/pdb2uniprot), described [here](https://www.biostars.org/p/9540519/#9540826).\n",
    "\n",
    "\n",
    "-----\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<p>If you haven't used one of these notebooks before, they're basically web pages in which you can write, edit, and run live code. They're meant to encourage experimentation, so don't feel nervous. Just try running a few cells and see what happens!.</p>\n",
    "\n",
    "<p>\n",
    "    Some tips:\n",
    "    <ul>\n",
    "        <li>Code cells have boxes around them.</li>\n",
    "        <li>To run a code cell, click on the cell and either click the <i class=\"fa-play fa\"></i> button on the toolbar above, or then hit <b>Shift+Enter</b>. The <b>Shift+Enter</b> combo will also move you to the next cell, so it's a quick way to work through the notebook. Selecting from the menu above the toolbar, <b>Cell</b> > <b>Run All</b> is a shortcut to trigger attempting to run all the cells in the notebook.</li>\n",
    "        <li>While a cell is running a <b>*</b> appears in the square brackets next to the cell. Once the cell has finished running the asterisk will be replaced with a number.</li>\n",
    "        <li>In most cases you'll want to start from the top of notebook and work your way down running each cell in turn. Later cells might depend on the results of earlier ones.</li>\n",
    "        <li>To edit a code cell, just click on it and type stuff. Remember to run the cell once you've finished editing.</li>\n",
    "    </ul>\n",
    "</p>\n",
    "</div>\n",
    "\n",
    "----\n",
    "\n",
    "Step through running the cells below. Then substitute in your PDB entry identifiers of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "\n",
    "## Preparation\n",
    "\n",
    "The packages needed to run PDBrenum are already installed.\n",
    "Let's also get some input data to use. The source we'll use also provides a script johnnytam100 made to do this task as well, and we'll use it to compare and contrast with that as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'pdb2uniprot'...\n",
      "remote: Enumerating objects: 29, done.\u001b[K\n",
      "remote: Counting objects: 100% (29/29), done.\u001b[K\n",
      "remote: Compressing objects: 100% (24/24), done.\u001b[K\n",
      "remote: Total 29 (delta 8), reused 0 (delta 0), pack-reused 0\u001b[K\n",
      "Unpacking objects: 100% (29/29), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/johnnytam100/pdb2uniprot.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's move those files, except the README, all to the same place as this notebook. (The README.md will be hidden before the main move commmand is run so it will be left & then it will be unhidden.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binder\t\t\t\t\t  pdb2uniprot\t       PDBrenum.py\n",
      "chainID_mapping_to_UniProt_id_demo.ipynb  pdb2uniprot_tam.py   README.md\n",
      "demo.ipynb\t\t\t\t  pdb_chain_table      src\n",
      "input.txt\t\t\t\t  pdb_chain_table.csv\n",
      "LICENSE\t\t\t\t\t  PDBrenum.ipynb\n"
     ]
    }
   ],
   "source": [
    "!mv pdb2uniprot/README.md pdb2uniprot/.README.md \n",
    "!mv pdb2uniprot/* .\n",
    "!mv pdb2uniprot/.README.md pdb2uniprot/README.md \n",
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see if getting all that worked, let's run the script and see the results. \n",
    "For the first input, we'll use `pdb_chain_table.csv` as used in the first option listed at https://github.com/johnnytam100/pdb2uniprot .  \n",
    "Let's look at the starting point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDB_ID,CHAIN_ID\n",
      "7DPA,A\n",
      "XXXX,X\n",
      "7DPA,B\n",
      "7DPA,Z\n",
      "1BZQ,A\n",
      "7dpa,z\n",
      "1bzq,A\n",
      "1BZQ,a\n",
      "1bzq,a"
     ]
    }
   ],
   "source": [
    "cat pdb_chain_table.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to actually run the first option listed at https://github.com/johnnytam100/pdb2uniprot :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping... 7DPA A\n",
      "mapping... XXXX X\n",
      "XXXX X PDB Not Found (HTTP Error 404). Skipped.\n",
      "mapping... 7DPA B\n",
      "mapping... 7DPA Z\n",
      "7DPA Z PDB Found but Chain Not Found. Skipped.\n",
      "mapping... 1BZQ A\n",
      "mapping... 7dpa z\n",
      "7dpa z PDB Found but Chain Not Found. Skipped.\n",
      "mapping... 1bzq A\n",
      "mapping... 1BZQ a\n",
      "mapping... 1bzq a\n"
     ]
    }
   ],
   "source": [
    "%run pdb2uniprot_tam.py --input pdb_chain_table.csv --pdb_col PDB_ID --chain_col CHAIN_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A new file named `pdb_chain_table_uniprot.csv`, based on the input name, `pdb_chain_table.csv`,  is generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mbinder\u001b[0m/                                   pdb_chain_table\n",
      "chainID_mapping_to_UniProt_id_demo.ipynb  pdb_chain_table.csv\n",
      "demo.ipynb                                pdb_chain_table_uniprot.csv\n",
      "\u001b[01;32minput.txt\u001b[0m*                                \u001b[01;32mPDBrenum.ipynb\u001b[0m*\n",
      "LICENSE                                   \u001b[01;32mPDBrenum.py\u001b[0m*\n",
      "\u001b[01;34mpdb2uniprot\u001b[0m/                              \u001b[01;32mREADME.md\u001b[0m*\n",
      "pdb2uniprot_tam.py                        \u001b[01;34msrc\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDB_ID,CHAIN_ID,uniprot\n",
      "7DPA,A,Q9H7D0\n",
      "XXXX,X,NaN\n",
      "7DPA,B,P63000\n",
      "7DPA,Z,NaN\n",
      "1BZQ,A,P61823\n",
      "7dpa,z,NaN\n",
      "1bzq,A,P61823\n",
      "1BZQ,a,P61823\n",
      "1bzq,a,P61823\n"
     ]
    }
   ],
   "source": [
    "cat pdb_chain_table_uniprot.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's easier to read if we read bring it into Pandas and take advantage of Jupyter's excellent handling of Pandas dataframes to view:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PDB_ID</th>\n",
       "      <th>CHAIN_ID</th>\n",
       "      <th>uniprot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>7DPA</td>\n",
       "      <td>A</td>\n",
       "      <td>Q9H7D0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>XXXX</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>7DPA</td>\n",
       "      <td>B</td>\n",
       "      <td>P63000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>7DPA</td>\n",
       "      <td>Z</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1BZQ</td>\n",
       "      <td>A</td>\n",
       "      <td>P61823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>7dpa</td>\n",
       "      <td>z</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1bzq</td>\n",
       "      <td>A</td>\n",
       "      <td>P61823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1BZQ</td>\n",
       "      <td>a</td>\n",
       "      <td>P61823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1bzq</td>\n",
       "      <td>a</td>\n",
       "      <td>P61823</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PDB_ID CHAIN_ID uniprot\n",
       "0   7DPA        A  Q9H7D0\n",
       "1   XXXX        X     NaN\n",
       "2   7DPA        B  P63000\n",
       "3   7DPA        Z     NaN\n",
       "4   1BZQ        A  P61823\n",
       "5   7dpa        z     NaN\n",
       "6   1bzq        A  P61823\n",
       "7   1BZQ        a  P61823\n",
       "8   1bzq        a  P61823"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "jtdf = pd.read_csv(\"pdb_chain_table_uniprot.csv\")\n",
    "jtdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Note that chain identifiers are actually case-sensitive, for example [5v2c](https://www.rcsb.org/structure/5V2C) has both chains designated A and a, and so I don't agree with CHAIN_ID of 'A' being same as 'a'.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pdb2uniprot_tam.py` will also take tables as tab-separated data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping... 7DPA A\n",
      "mapping... XXXX X\n",
      "XXXX X PDB Not Found (HTTP Error 404). Skipped.\n",
      "mapping... 7DPA B\n",
      "mapping... 7DPA Z\n",
      "7DPA Z PDB Found but Chain Not Found. Skipped.\n",
      "mapping... 1BZQ A\n",
      "mapping... 7dpa z\n",
      "7dpa z PDB Found but Chain Not Found. Skipped.\n",
      "mapping... 1bzq A\n",
      "mapping... 1BZQ a\n",
      "mapping... 1bzq a\n"
     ]
    }
   ],
   "source": [
    "%run pdb2uniprot_tam.py --input pdb_chain_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pdb\tchain\tuniprot\n",
      "7DPA\tA\tQ9H7D0\n",
      "7DPA\tB\tP63000\n",
      "1BZQ\tA\tP61823\n",
      "1bzq\tA\tP61823\n",
      "1BZQ\ta\tP61823\n",
      "1bzq\ta\tP61823\n"
     ]
    }
   ],
   "source": [
    "cat pdb_chain_table_uniprot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we leave the preparation section, let's create a list of PDB codes for later use. We can use jtdf to do that.\n",
    "\n",
    "One option is to use:\n",
    "\n",
    "```python\n",
    "extracted = jtdf[[\"PDB_ID\"]]\n",
    "extracted.to_csv(\"codes.txt\", header = False, index = False)\n",
    "```\n",
    "\n",
    "But that's going to result in `codes.txt` with several duplicates. Let's make the extraction step more complex to get a simpler list of codes. In the more complex version, we'll make all the codes lowercase and then drop the dupliates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "jtdf[\"PDB_ID\"] = jtdf[\"PDB_ID\"].str.lower()\n",
    "extracted = jtdf[[\"PDB_ID\"]].drop_duplicates()\n",
    "extracted.to_csv(\"codes.txt\", header = False, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7dpa\n",
      "xxxx\n",
      "1bzq\n"
     ]
    }
   ],
   "source": [
    "cat codes.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that if the file where the PDB codes are stored had just been a single column of PDB ids with each one on a separate line, like we just made with `codes.txt`, then it would have been easy with the following code to read that into Python as a list without invoking Pandas and using only the core Python library:\n",
    "\n",
    "```python\n",
    "input_file_name = \"codes.txt\"\n",
    "collected_ids = []\n",
    "with open(input_file_name, 'r') as file_in_stream:\n",
    "    for line in file_in_stream:\n",
    "        collected_ids.append(line.strip())\n",
    "```\n",
    "\n",
    "I'm providing that here as another option since who knows what form of actual input you made have to deal with and some may find direct Python easier to adapt.  \n",
    "Because we are dealing with tables to read in the data that's generated as a by-product of running PDBrenum and that data is in text table form, we'll need Pandas installed and so it isn't really feasible to avoid using Pandas in this effort. However, hopefully featuring the option with the core Python library is enough to give you a sense they are options beyond Pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------\n",
    "\n",
    "# Quickstart overview: use of PDBrenum to map PDB and chain IDs to UniProt IDs\n",
    "\n",
    "Now that the preparation steps are complete, this sub-section is meant to quickly show the code and the process to those who are familiar with PDBrenum use/SIFTS data and Python. (For example, you may have come from the Biostars post [Mapping PDB ID + chain ID to UniProt ID](https://www.biostars.org/p/9540519/#9540582) and just want to see the 'typical' route all together.) \n",
    "\n",
    "If you know you aren't going to follow it, you may skip running the code in this sub-section and go right onto the next sub-section.\n",
    "\n",
    "If you want to understand what this code block below is doing or understand the many ways you can adapt it. Or even see varations, read on the further sections below.\n",
    "\n",
    "This example will process one of the inputs that `pdb2uniprot_tam.py` uses to demonstrate how it works using one of the straighforward processes that are futher explored below in this notebook. Click in the cell and type `shift+enter` to run it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading PDB files: 100%|██████████| 3/3 [00:00<00:00,  6.22it/s]\n",
      "Downloading PDB files: 100%|██████████| 3/3 [00:00<00:00,  6.77it/s]\n",
      "Downloading PDB files: 100%|██████████| 3/3 [00:00<00:00,  6.97it/s]\n",
      "Downloading SIFTS files: 100%|██████████| 3/3 [00:00<00:00,  5.07it/s]\n",
      "Downloading SIFTS files: 100%|██████████| 3/3 [00:00<00:00,  5.91it/s]\n",
      "Downloading SIFTS files: 100%|██████████| 3/3 [00:00<00:00,  5.94it/s]\n",
      "Renumbering PDB files: 100%|██████████| 2/2 [00:07<00:00,  3.97s/it]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "input_df = pd.read_csv(\"pdb_chain_table.csv\")\n",
    "input_df[\"PDB_ID\"] = input_df[\"PDB_ID\"].str.lower()\n",
    "codes_list = input_df[[\"PDB_ID\"]].drop_duplicates().PDB_ID.tolist()\n",
    "codes_list_as_text = \" \".join(codes_list)\n",
    "%run PDBrenum.py -rfla {codes_list_as_text} -PDB\n",
    "df = pd.read_fwf(\"log_corrected.txt\", )\n",
    "dfsub = df[['PDB_id', 'chain_PDB','UniProt']]\n",
    "df_dict = dfsub.groupby('PDB_id').apply(lambda x: dict(zip(x.chain_PDB, x.UniProt))).to_dict()\n",
    "def lookup_id(items):\n",
    "    '''\n",
    "    takes a row with PDB_ID and CHAIN_ID and returns corresponding UniProt ID\n",
    "    '''\n",
    "    pdb_id = items[0].lower()\n",
    "    chain_id = items[1] \n",
    "    if pdb_id not in df_dict:\n",
    "        return 'NA'\n",
    "    if chain_id not in df_dict[pdb_id]:\n",
    "        return 'NA'\n",
    "    uniprot_id = df_dict[pdb_id][chain_id]\n",
    "    return uniprot_id\n",
    "result_df = input_df.copy()\n",
    "result_df['UniProt'] = result_df.apply(lookup_id, axis=1)\n",
    "result_df.to_csv(\"result_with_uniprot.tsv\",index=False, sep = \"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To show the results here, run the next cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDB_ID\tCHAIN_ID\tUniProt\n",
      "7dpa\tA\tQ9H7D0\n",
      "xxxx\tX\tNA\n",
      "7dpa\tB\tP63000\n",
      "7dpa\tZ\tNA\n",
      "1bzq\tA\tP61823\n",
      "7dpa\tz\tNA\n",
      "1bzq\tA\tP61823\n",
      "1bzq\ta\tNA\n",
      "1bzq\ta\tNA\n"
     ]
    }
   ],
   "source": [
    "!cat result_with_uniprot.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read on for more insight or how you can adapt it or code below for your specific use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "Notes on Snakemake and PDBrenum to mapping chain IDs to UniProt IDs\n",
    "---------------\n",
    "\n",
    "If you are familiar with any of my other scripts and workflows, you may know I like snakemake for pulling things together into a useable pipeline. So why not here? It certainly could be done. One of the main benefits of snakemake is that upon change in files, say adding input, it will analyze your pipeline for any product it doesn't have have and make just that product. However, to get that benefit here in conjunction with PDBrenum use, it would necessitate handling a lot of steps that aren't already there. Frankly, PDBrenum is set up to be a pipeline in itself. The steps needed to process a lot pod PDB files are straightforward and easy to write/adapt. It seems making it a snakemake wokflow at this time isn't worth the effort.\n",
    "\n",
    "\n",
    "----\n",
    "\n",
    "## One way to use PDBrenum to map chain IDs to UniProt IDs: letting PDBrenum handle several PDB codes\n",
    "\n",
    "Now that the preparation steps are complete, we have input files and any other items needed to work through the rest of this notebook. Let's get started.\n",
    "\n",
    "How exactly the iterating on different PDB files is handled is one consideration when deciding what way you want to integrate the use of PDBrenum for mapping into your work. And how you handle it might come down to what else you are doing when you need the mappings, and so I'll show first where PDBrenum's handling of multiple PDB identifiers is used and then later we'll iterate on each PDB file, running PDBrenum each time instead of just once.\n",
    "\n",
    "First we'll need the PDB codes, and so we'll get them from the example input. The example input has two entries on each line: the PDB file identifier and the chain designation. After we use the double columned example input, we'll demonstrate using just the PDB codes.\n",
    "\n",
    "### A: Using double-column input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use `pdb_chain_table.csv` and `pdb_chain_table` as examples for variations on double-column input. Both input options contain a PDB id and a corresponding chain id on each line, as was shown above. The first is comma delimited and the second is tab delimited.\n",
    "\n",
    "We'll need the PDB codes that we'll supply to the main PDBrenum command to accomplish the main step. We can use a variation on the first steps we used when we were making `codes.txt` in the preparation section. We'll make a Python list with the PDB id codes for now. The PDB id codes will be in lowercase to standardize them easily so we can remove duplicates or see anythign out of the ordinary more clearly, i.e., less chance of confusing the letter`O` for a zero, etc.. We'll first use the variation on the steps in the preparation section, using a dataframe already define there, to highlight how Pandas makes it easy and to highlight the steps separate from reading in the input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['7dpa', 'xxxx', '1bzq']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "jtdf[\"PDB_ID\"] = jtdf[\"PDB_ID\"].str.lower()\n",
    "codes_list = jtdf[[\"PDB_ID\"]].drop_duplicates().PDB_ID.tolist()\n",
    "codes_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that because the dataframe `jtdf` came from a modified version of the text file `pdb_chain_table.csv` and only concerns the column with the PDB id codes, it's equivalent to reading in the PDB id codes from `pdb_chain_table.csv`. Now that I highlighted just those two steps to make it clear, it's best to cover how to start with the input file as that is where you'd be if you were starting with your own PDB id codes and chain identifiers to process\n",
    "\n",
    "\n",
    "\n",
    "So we'll read in from the actual input file now using Pandas similar to what was done in the preparation and add in the steps just highlighted above. Let's make `codes_list` that way by running the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['7dpa', 'xxxx', '1bzq']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "input_df = pd.read_csv(\"pdb_chain_table.csv\")\n",
    "input_df[\"PDB_ID\"] = input_df[\"PDB_ID\"].str.lower()\n",
    "codes_list = input_df[[\"PDB_ID\"]].drop_duplicates().PDB_ID.tolist()\n",
    "codes_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading PDB files: 100%|██████████| 3/3 [00:00<00:00,  6.90it/s]\n",
      "Downloading PDB files: 100%|██████████| 3/3 [00:00<00:00,  6.56it/s]\n",
      "Downloading PDB files: 100%|██████████| 3/3 [00:00<00:00,  6.77it/s]\n",
      "Downloading SIFTS files: 100%|██████████| 3/3 [00:00<00:00,  5.84it/s]\n",
      "Downloading SIFTS files: 100%|██████████| 3/3 [00:00<00:00,  5.89it/s]\n",
      "Downloading SIFTS files: 100%|██████████| 3/3 [00:00<00:00,  5.96it/s]\n",
      "Renumbering PDB files: 100%|██████████| 2/2 [00:07<00:00,  3.67s/it]\n"
     ]
    }
   ],
   "source": [
    "codes_list_as_text = \" \".join(codes_list)\n",
    "%run PDBrenum.py -rfla {codes_list_as_text} -PDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(The purpose/use of the `-rfla` flag was covered in [Demo of PDBrenum in your broswer via MyBinder.org](demo.ipynb).)\n",
    "\n",
    "The file created `log_corrected.txt` has the information we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SP PDB_id chain_PDB   chain_auth  UniProt             SwissProt              uni_len chain_len     renum 5k_or_50k\n",
      "+  7dpa   A           A           Q9H7D0              DOCK5_HUMAN               1642      1642         0         0\n",
      "+  7dpa   B           B           P63000              RAC1_HUMAN                 177       177         0         0\n",
      "+  7dpa   C           C           Q92556              ELMO1_HUMAN                198       198         0         0\n",
      "+  7dpa   D           D           Q9H7D0              DOCK5_HUMAN               1642      1642         0         0\n",
      "+  7dpa   E           E           P63000              RAC1_HUMAN                 177       177         0         0\n",
      "+  7dpa   F           F           Q92556              ELMO1_HUMAN                198       198         0         0\n",
      "+  1bzq   A           A           P61823              RNAS1_BOVIN                124       124       124         0\n",
      "+  1bzq   B           B           P61823              RNAS1_BOVIN                124       124       124         0\n",
      "+  1bzq   C           C           P61823              RNAS1_BOVIN                124       124       124         0\n",
      "+  1bzq   D           D           P61823              RNAS1_BOVIN                124       124       124         0\n"
     ]
    }
   ],
   "source": [
    "cat log_corrected.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table in `cat log_corrected.txt` shown above is a fixed-width format text table that Pandas can read in.  \n",
    "We can then use that Pandas dataframe to organize the appropriate data for ease of access as we try to relate to the input lines. The organizaing consists of making a dictionary of dictionaries with the assgnments per PDB file. The PDB codes will be the keys of the main overarching dictionary. Then in that overarching dictionary for each PDB code the values contained will be dictionary, with the chain designations as keys and the corresponding UniProt id as the value.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1bzq': {'A': 'P61823', 'B': 'P61823', 'C': 'P61823', 'D': 'P61823'},\n",
       " '7dpa': {'A': 'Q9H7D0',\n",
       "  'B': 'P63000',\n",
       "  'C': 'Q92556',\n",
       "  'D': 'Q9H7D0',\n",
       "  'E': 'P63000',\n",
       "  'F': 'Q92556'}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_fwf(\"log_corrected.txt\", ) # based on https://stackoverflow.com/a/41509522/8508004\n",
    "# We only need the three columns that have 'PDB_id', 'chain_PDB', and 'UniProt'\n",
    "dfsub = df[['PDB_id', 'chain_PDB','UniProt']]\n",
    "#df_dict = dfsub.to_dict(orient='records') # If you prefer each row as a dictionary\n",
    "#df_dict = dfsub.groupby('PDB_id').apply(lambda x: [dict(zip(x.chain_PDB, x.UniProt))]).to_dict() # based on https://stackoverflow.com/a/41064974/8508004; \n",
    "# it makes a dictionary of a list of dictionaries\n",
    "df_dict = dfsub.groupby('PDB_id').apply(lambda x: dict(zip(x.chain_PDB, x.UniProt))).to_dict() # based on https://stackoverflow.com/a/41064974/8508004\n",
    "# {k: [v.to_dict()] for k, v in dfsub.set_index(['PDB_id', 'chain_PDB']).UniProt.unstack(0).iteritems()}  # based on https://stackoverflow.com/a/41065429/8508004;\n",
    "# it makes a dictionary of a list of dictionaries but note that it tries to make all sub dictionaries have same chain elementes it seems and so puts `nan` for chains that don't have UniProt id values\n",
    "#{k: v.to_dict() for k, v in dfsub.set_index(['PDB_id', 'chain_PDB']).UniProt.unstack(0).iteritems()}}  # based on https://stackoverflow.com/a/41065429/8508004;\n",
    "# but see caveat about chain elements above the dictionary comprehenseion\n",
    "df_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the assignments per PDB file, we can read in the input file and then use that to make a table with the UniProt id added. (Because I gave options for getting the PDB codes earlier for the above steps, I'm not outright assuming `input_df` was already defined.) First, we'll do that with the comma delimited version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "input_df = pd.read_csv(\"pdb_chain_table.csv\")\n",
    "def lookup_id(items):\n",
    "    '''\n",
    "    takes a row with PDB_ID and CHAIN_ID and returns corresponding UniProt ID\n",
    "    '''\n",
    "    pdb_id = items[0].lower()\n",
    "    chain_id = items[1] \n",
    "    if pdb_id not in df_dict:\n",
    "        return 'NA'\n",
    "    if chain_id not in df_dict[pdb_id]:\n",
    "        return 'NA'\n",
    "    uniprot_id = df_dict[pdb_id][chain_id]\n",
    "    return uniprot_id\n",
    "result_df = input_df.copy()\n",
    "result_df['UniProt'] = result_df.copy().apply(lookup_id, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PDB_ID</th>\n",
       "      <th>CHAIN_ID</th>\n",
       "      <th>UniProt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>7DPA</td>\n",
       "      <td>A</td>\n",
       "      <td>Q9H7D0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>XXXX</td>\n",
       "      <td>X</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>7DPA</td>\n",
       "      <td>B</td>\n",
       "      <td>P63000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>7DPA</td>\n",
       "      <td>Z</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1BZQ</td>\n",
       "      <td>A</td>\n",
       "      <td>P61823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>7dpa</td>\n",
       "      <td>z</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1bzq</td>\n",
       "      <td>A</td>\n",
       "      <td>P61823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1BZQ</td>\n",
       "      <td>a</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1bzq</td>\n",
       "      <td>a</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PDB_ID CHAIN_ID UniProt\n",
       "0   7DPA        A  Q9H7D0\n",
       "1   XXXX        X      NA\n",
       "2   7DPA        B  P63000\n",
       "3   7DPA        Z      NA\n",
       "4   1BZQ        A  P61823\n",
       "5   7dpa        z      NA\n",
       "6   1bzq        A  P61823\n",
       "7   1BZQ        a      NA\n",
       "8   1bzq        a      NA"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same main code will work for the tab-delimited data. The only change needed is specifying the delimiter for reading in to Python (Pandas type data, specifically). We'll tell Pandas the delimiter is a tab, which is signaled with `/t`. The tab-delimited input file provided by  [Johnny Tam's pdb2uniprot repository](https://github.com/johnnytam100/pdb2uniprot), that we are using as a source of example data, also lacks the column headings and so we need to add those when reading the tab-delimited file. (Note that is the file `pdb_chain_table` had an extension of `.tsv` it would be more obvious and indeed Jupyter would provide conevenience viewers that work with it, but it's not necessary since we know from [Johnny Tam's pdb2uniprot repository](https://github.com/johnnytam100/pdb2uniprot) that it is the 'tab-delimited table')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PDB_ID</th>\n",
       "      <th>CHAIN_ID</th>\n",
       "      <th>UniProt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>7DPA</td>\n",
       "      <td>A</td>\n",
       "      <td>Q9H7D0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>XXXX</td>\n",
       "      <td>X</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>7DPA</td>\n",
       "      <td>B</td>\n",
       "      <td>P63000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>7DPA</td>\n",
       "      <td>Z</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1BZQ</td>\n",
       "      <td>A</td>\n",
       "      <td>P61823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>7dpa</td>\n",
       "      <td>z</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1bzq</td>\n",
       "      <td>A</td>\n",
       "      <td>P61823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1BZQ</td>\n",
       "      <td>a</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1bzq</td>\n",
       "      <td>a</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PDB_ID CHAIN_ID UniProt\n",
       "0   7DPA        A  Q9H7D0\n",
       "1   XXXX        X      NA\n",
       "2   7DPA        B  P63000\n",
       "3   7DPA        Z      NA\n",
       "4   1BZQ        A  P61823\n",
       "5   7dpa        z      NA\n",
       "6   1bzq        A  P61823\n",
       "7   1BZQ        a      NA\n",
       "8   1bzq        a      NA"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Using tab delimited input\n",
    "import pandas as pd\n",
    "input_df = pd.read_csv(\"pdb_chain_table\", sep=\"\\t\", names = [\"PDB_ID\",\"CHAIN_ID\"])\n",
    "def lookup_id(items):\n",
    "    '''\n",
    "    takes a row with PDB_ID and CHAIN_ID and returns corresponding UniProt ID\n",
    "    '''\n",
    "    pdb_id = items[0].lower()\n",
    "    chain_id = items[1] \n",
    "    if pdb_id not in df_dict:\n",
    "        return 'NA'\n",
    "    if chain_id not in df_dict[pdb_id]:\n",
    "        return 'NA'\n",
    "    uniprot_id = df_dict[pdb_id][chain_id]\n",
    "    return uniprot_id\n",
    "result_df = input_df.copy()\n",
    "result_df['UniProt'] = result_df.apply(lookup_id, axis=1)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the only real change relative the code showed earlier is this line:\n",
    "\n",
    "```python\n",
    "input_df = pd.read_csv(\"pdb_chain_table\", sep=\"\\t\", names = [\"PDB_ID\",\"CHAIN_ID\"])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that pdb2uniprot makes the output as a data text table file with the choice of having the header or not.  \n",
    "That can easily be done with the Pandas dataframe we've made with the two types of input. Demonstrating that with the current dataframe in memory, first we'll save the output file with the header (`index=False` means we don't want the row numbers that the dataframe has, which are a Pandas `index` object):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv(\"result_with_uniprot.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can show that worked by looking at the contents here by running the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDB_ID,CHAIN_ID,UniProt\n",
      "7DPA,A,Q9H7D0\n",
      "XXXX,X,NA\n",
      "7DPA,B,P63000\n",
      "7DPA,Z,NA\n",
      "1BZQ,A,P61823\n",
      "7dpa,z,NA\n",
      "1bzq,A,P61823\n",
      "1BZQ,a,NA\n",
      "1bzq,a,NA\n"
     ]
    }
   ],
   "source": [
    "!cat result_with_uniprot.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can make that tab-delimited if we prefer by specifying the separator as we did when reading in the tab-separated input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv(\"result_with_uniprot.tsv\",index=False, sep = \"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verifying that here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDB_ID\tCHAIN_ID\tUniProt\n",
      "7DPA\tA\tQ9H7D0\n",
      "XXXX\tX\tNA\n",
      "7DPA\tB\tP63000\n",
      "7DPA\tZ\tNA\n",
      "1BZQ\tA\tP61823\n",
      "7dpa\tz\tNA\n",
      "1bzq\tA\tP61823\n",
      "1BZQ\ta\tNA\n",
      "1bzq\ta\tNA\n"
     ]
    }
   ],
   "source": [
    "!cat result_with_uniprot.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As I mentioned above, Johnny Tam's pdb2uniprot makes the output as a data text table file with the choice of not having the header. That can easily be done with the Pandas dataframe by including `header = False` in the call to the method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv(\"result_with_uniprot_no_header.tsv\",index=False, sep = \"\\t\", header = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7DPA\tA\tQ9H7D0\n",
      "XXXX\tX\tNA\n",
      "7DPA\tB\tP63000\n",
      "7DPA\tZ\tNA\n",
      "1BZQ\tA\tP61823\n",
      "7dpa\tz\tNA\n",
      "1bzq\tA\tP61823\n",
      "1BZQ\ta\tNA\n",
      "1bzq\ta\tNA\n"
     ]
    }
   ],
   "source": [
    "!cat result_with_uniprot_no_header.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B: Using a list of PDB codes\n",
    "\n",
    "Imagine you just had a list of PDB codes and you wanted the information for all chains present. We'll use the list of codes we made in the the last part of the preparation section to demonstrate this situation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7dpa\n",
      "xxxx\n",
      "1bzq\n"
     ]
    }
   ],
   "source": [
    "# `codes.txt` was made in the preparation section; as a reminder. Here are the contents:\n",
    "!cat codes.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This approach really follows from the beginning of the section 'A' just covered. Because we want all the results, we don't need to look up anything and we can just use the reduced version of all the data in `log_corrected.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading PDB files: 100%|██████████| 3/3 [00:00<00:00,  6.91it/s]\n",
      "Downloading PDB files: 100%|██████████| 3/3 [00:00<00:00,  6.65it/s]\n",
      "Downloading PDB files: 100%|██████████| 3/3 [00:00<00:00,  7.00it/s]\n",
      "Downloading SIFTS files: 100%|██████████| 3/3 [00:00<00:00,  5.97it/s]\n",
      "Downloading SIFTS files: 100%|██████████| 3/3 [00:00<00:00,  5.98it/s]\n",
      "Downloading SIFTS files: 100%|██████████| 3/3 [00:00<00:00,  5.94it/s]\n",
      "Renumbering PDB files: 100%|██████████| 2/2 [00:07<00:00,  3.79s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PDB_id</th>\n",
       "      <th>chain_PDB</th>\n",
       "      <th>UniProt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>7dpa</td>\n",
       "      <td>A</td>\n",
       "      <td>Q9H7D0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>7dpa</td>\n",
       "      <td>B</td>\n",
       "      <td>P63000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>7dpa</td>\n",
       "      <td>C</td>\n",
       "      <td>Q92556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>7dpa</td>\n",
       "      <td>D</td>\n",
       "      <td>Q9H7D0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>7dpa</td>\n",
       "      <td>E</td>\n",
       "      <td>P63000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>7dpa</td>\n",
       "      <td>F</td>\n",
       "      <td>Q92556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1bzq</td>\n",
       "      <td>A</td>\n",
       "      <td>P61823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1bzq</td>\n",
       "      <td>B</td>\n",
       "      <td>P61823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1bzq</td>\n",
       "      <td>C</td>\n",
       "      <td>P61823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1bzq</td>\n",
       "      <td>D</td>\n",
       "      <td>P61823</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PDB_id chain_PDB UniProt\n",
       "0   7dpa         A  Q9H7D0\n",
       "1   7dpa         B  P63000\n",
       "2   7dpa         C  Q92556\n",
       "3   7dpa         D  Q9H7D0\n",
       "4   7dpa         E  P63000\n",
       "5   7dpa         F  Q92556\n",
       "6   1bzq         A  P61823\n",
       "7   1bzq         B  P61823\n",
       "8   1bzq         C  P61823\n",
       "9   1bzq         D  P61823"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_simple = pd.read_csv('codes.txt', header=None, names = ['PDB_ids'])\n",
    "codes_list = df_simple['PDB_ids'].to_list()\n",
    "codes_list_as_text = \" \".join(codes_list)\n",
    "%run PDBrenum.py -rfla {codes_list_as_text} -PDB\n",
    "df = pd.read_fwf(\"log_corrected.txt\", )\n",
    "df_results = df[['PDB_id', 'chain_PDB','UniProt']]\n",
    "df_results.to_csv(\"all_result_with_uniprot.tsv\",index=False, sep = \"\\t\")\n",
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We included making a text file above for options for downstream use. Running the next cell will show the contents here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDB_id\tchain_PDB\tUniProt\n",
      "7dpa\tA\tQ9H7D0\n",
      "7dpa\tB\tP63000\n",
      "7dpa\tC\tQ92556\n",
      "7dpa\tD\tQ9H7D0\n",
      "7dpa\tE\tP63000\n",
      "7dpa\tF\tQ92556\n",
      "1bzq\tA\tP61823\n",
      "1bzq\tB\tP61823\n",
      "1bzq\tC\tP61823\n",
      "1bzq\tD\tP61823\n"
     ]
    }
   ],
   "source": [
    "!cat all_result_with_uniprot.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It will look better if you double-click on `all_result_with_uniprot.tsv` listed in the file browser on the left and open it with JupyterLab's TSV viewer, and then return here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read in the input file line per line without Pandas.**  \n",
    "Since we were already usng Pandas, I simply used Pandas to read in the input data, too. However, as I pointed out earlier in this notebook theres other routes to read such a single-column, like-like text file with an item on each line. For example, it would have been easy with the following code to read `codes.txt` into Python as a list without invoking Pandas and using only the core Python library:\n",
    "\n",
    "```python\n",
    "input_file_name = \"codes.txt\"\n",
    "collected_ids = []\n",
    "with open(input_file_name, 'r') as file_in_stream:\n",
    "    for line in file_in_stream:\n",
    "        collected_ids.append(line.strip())\n",
    "```\n",
    "\n",
    "Plugging that in instead of using Pandas, the code just demonstrate above to get all the chains and ID mapping for each PDB would be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading PDB files: 100%|██████████| 3/3 [00:00<00:00,  6.46it/s]\n",
      "Downloading PDB files: 100%|██████████| 3/3 [00:00<00:00,  6.85it/s]\n",
      "Downloading PDB files: 100%|██████████| 3/3 [00:00<00:00,  7.01it/s]\n",
      "Downloading SIFTS files: 100%|██████████| 3/3 [00:00<00:00,  5.82it/s]\n",
      "Downloading SIFTS files: 100%|██████████| 3/3 [00:00<00:00,  5.88it/s]\n",
      "Downloading SIFTS files: 100%|██████████| 3/3 [00:00<00:00,  6.01it/s]\n",
      "Renumbering PDB files: 100%|██████████| 2/2 [00:08<00:00,  4.13s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PDB_id</th>\n",
       "      <th>chain_PDB</th>\n",
       "      <th>UniProt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>7dpa</td>\n",
       "      <td>A</td>\n",
       "      <td>Q9H7D0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>7dpa</td>\n",
       "      <td>B</td>\n",
       "      <td>P63000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>7dpa</td>\n",
       "      <td>C</td>\n",
       "      <td>Q92556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>7dpa</td>\n",
       "      <td>D</td>\n",
       "      <td>Q9H7D0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>7dpa</td>\n",
       "      <td>E</td>\n",
       "      <td>P63000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>7dpa</td>\n",
       "      <td>F</td>\n",
       "      <td>Q92556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1bzq</td>\n",
       "      <td>A</td>\n",
       "      <td>P61823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1bzq</td>\n",
       "      <td>B</td>\n",
       "      <td>P61823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1bzq</td>\n",
       "      <td>C</td>\n",
       "      <td>P61823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1bzq</td>\n",
       "      <td>D</td>\n",
       "      <td>P61823</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PDB_id chain_PDB UniProt\n",
       "0   7dpa         A  Q9H7D0\n",
       "1   7dpa         B  P63000\n",
       "2   7dpa         C  Q92556\n",
       "3   7dpa         D  Q9H7D0\n",
       "4   7dpa         E  P63000\n",
       "5   7dpa         F  Q92556\n",
       "6   1bzq         A  P61823\n",
       "7   1bzq         B  P61823\n",
       "8   1bzq         C  P61823\n",
       "9   1bzq         D  P61823"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "input_file_name = \"codes.txt\"\n",
    "collected_ids = []\n",
    "with open(input_file_name, 'r') as file_in_stream:\n",
    "    for line in file_in_stream:\n",
    "        collected_ids.append(line.strip())\n",
    "codes_list_as_text = \" \".join(collected_ids)\n",
    "%run PDBrenum.py -rfla {codes_list_as_text} -PDB\n",
    "dfB = pd.read_fwf(\"log_corrected.txt\", )\n",
    "df_resultsB = df[['PDB_id', 'chain_PDB','UniProt']]\n",
    "df_resultsB.to_csv(\"alt_all_result_with_uniprot.tsv\",index=False, sep = \"\\t\")\n",
    "df_resultsB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDB_id\tchain_PDB\tUniProt\n",
      "7dpa\tA\tQ9H7D0\n",
      "7dpa\tB\tP63000\n",
      "7dpa\tC\tQ92556\n",
      "7dpa\tD\tQ9H7D0\n",
      "7dpa\tE\tP63000\n",
      "7dpa\tF\tQ92556\n",
      "1bzq\tA\tP61823\n",
      "1bzq\tB\tP61823\n",
      "1bzq\tC\tP61823\n",
      "1bzq\tD\tP61823\n"
     ]
    }
   ],
   "source": [
    "!cat alt_all_result_with_uniprot.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another way to use PDBrenum to map chain IDs to UniProt IDs: iterating through running PDBrenum with one PDB code at a time and further mining the generated by by-product information in turn\n",
    "\n",
    "Using PDBrenum as it was above means it handles multiple PDB ids by default and handles issues with codes that aren't true PBB codes without you needing to handle that aspect. Those are niceties that make the script user-friendly that you don't need to worry about. **Plus, when you can it makes more sense to rely on code someone has written and released rather then writing everything yourself.** Code that you don't need to write or maintain that does what you need is a gift.\n",
    "\n",
    "However, in the itnerest of options, you may wish to only run PDBrnum on individual PDB files each time and process the data in `log_corrected.txt` for each individual PDB id and then combine the details subsequently. For example, you may be doing something else with the PDB file or PDB id in parallel that you want to combine the mappng of the chain ID to UniProt as well. Or the data you want to mine from PDBrenum results or `log_corrected.txt` turns out to be easier when there's only one PDB id being processed at a time. This section will show how to run the PDBrenum script with each PDB id and get the mapping of the chain IDs to UniProt IDs out.\n",
    "\n",
    "We'll do that with both the double-column input type and the single column to match with sections **A** and **B** above.\n",
    "\n",
    "### A: Using double-column input and iterating on each PDB id code running PDBrenum one at time\n",
    "\n",
    "First we'll adapt the typical route listed in the Overivew and actually encountered first in this notbeook. So essentially instead of `%run PDBrenum.py -rfla {codes_list_as_text} -PDB` to supply all the PDB ids at once and then using that as a block, we'll loop on each like this:\n",
    "\n",
    "```python\n",
    "for pdb_id in codes_list:\n",
    "    %run PDBrenum.py {pdb_id}\n",
    "    #...process by-products of pdbrenum with out goal in mind...#\n",
    "```\n",
    "\n",
    "Run the next cell to see this in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading mmCIF files: 100%|██████████| 1/1 [00:00<00:00,  2.26it/s]\n",
      "Downloading SIFTS files: 100%|██████████| 1/1 [00:00<00:00,  1.92it/s]\n",
      "Renumbering mmCIF files: 100%|██████████| 1/1 [00:02<00:00,  3.00s/it]\n",
      "Checking mmCIF files: 100%|██████████| 1/1 [00:00<00:00,  1.36it/s]\n",
      "Downloading mmCIF files: 100%|██████████| 1/1 [00:00<00:00,  5.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  SP PDB_id chain_PDB chain_auth UniProt    SwissProt  uni_len  chain_len  \\\n",
      "0  +   7dpa         A          A  Q9H7D0  DOCK5_HUMAN     1642       1642   \n",
      "1  +   7dpa         B          B  P63000   RAC1_HUMAN      177        177   \n",
      "2  +   7dpa         C          C  Q92556  ELMO1_HUMAN      198        198   \n",
      "3  +   7dpa         D          D  Q9H7D0  DOCK5_HUMAN     1642       1642   \n",
      "4  +   7dpa         E          E  P63000   RAC1_HUMAN      177        177   \n",
      "5  +   7dpa         F          F  Q92556  ELMO1_HUMAN      198        198   \n",
      "\n",
      "   renum  5k_or_50k  \n",
      "0      0          0  \n",
      "1      0          0  \n",
      "2      0          0  \n",
      "3      0          0  \n",
      "4      0          0  \n",
      "5      0          0  \n",
      "{'7dpa': {'A': 'Q9H7D0', 'B': 'P63000', 'C': 'Q92556', 'D': 'Q9H7D0', 'E': 'P63000', 'F': 'Q92556'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading mmCIF files: 100%|██████████| 1/1 [00:00<00:00,  5.86it/s]\n",
      "Downloading mmCIF files: 100%|██████████| 1/1 [00:00<00:00,  5.79it/s]\n",
      "Downloading SIFTS files: 100%|██████████| 1/1 [00:00<00:00,  4.77it/s]\n",
      "Downloading SIFTS files: 100%|██████████| 1/1 [00:00<00:00,  4.72it/s]\n",
      "Downloading SIFTS files: 100%|██████████| 1/1 [00:00<00:00,  4.78it/s]\n",
      "Renumbering mmCIF files: 0it [00:00, ?it/s]\n",
      "Checking mmCIF files: 100%|██████████| 1/1 [00:00<00:00,  1.29it/s]\n",
      "Downloading mmCIF files:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [SP, PDB_id, chain_PDB, chain_auth, UniProt, SwissProt, uni_len, chain_len, renum, 5k_or_50k]\n",
      "Index: []\n",
      "{}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading mmCIF files: 100%|██████████| 1/1 [00:00<00:00,  3.07it/s]\n",
      "Downloading SIFTS files: 100%|██████████| 1/1 [00:00<00:00,  2.35it/s]\n",
      "Renumbering mmCIF files: 100%|██████████| 1/1 [00:02<00:00,  2.37s/it]\n",
      "Checking mmCIF files: 100%|██████████| 2/2 [00:00<00:00,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  SP PDB_id chain_PDB chain_auth UniProt    SwissProt  uni_len  chain_len  \\\n",
      "0  +   1bzq         A          A  P61823  RNAS1_BOVIN      124        124   \n",
      "1  +   1bzq         B          B  P61823  RNAS1_BOVIN      124        124   \n",
      "2  +   1bzq         C          C  P61823  RNAS1_BOVIN      124        124   \n",
      "3  +   1bzq         D          D  P61823  RNAS1_BOVIN      124        124   \n",
      "\n",
      "   renum  5k_or_50k  \n",
      "0    124          0  \n",
      "1    124          0  \n",
      "2    124          0  \n",
      "3    124          0  \n",
      "{'1bzq': {'A': 'P61823', 'B': 'P61823', 'C': 'P61823', 'D': 'P61823'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PDB_ID</th>\n",
       "      <th>CHAIN_ID</th>\n",
       "      <th>UniProt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>7dpa</td>\n",
       "      <td>A</td>\n",
       "      <td>Q9H7D0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>X</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>7dpa</td>\n",
       "      <td>B</td>\n",
       "      <td>P63000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>7dpa</td>\n",
       "      <td>Z</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1bzq</td>\n",
       "      <td>A</td>\n",
       "      <td>P61823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>7dpa</td>\n",
       "      <td>z</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1bzq</td>\n",
       "      <td>A</td>\n",
       "      <td>P61823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1bzq</td>\n",
       "      <td>a</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1bzq</td>\n",
       "      <td>a</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PDB_ID CHAIN_ID UniProt\n",
       "0   7dpa        A  Q9H7D0\n",
       "1   xxxx        X      NA\n",
       "2   7dpa        B  P63000\n",
       "3   7dpa        Z      NA\n",
       "4   1bzq        A  P61823\n",
       "5   7dpa        z      NA\n",
       "6   1bzq        A  P61823\n",
       "7   1bzq        a      NA\n",
       "8   1bzq        a      NA"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "input_df = pd.read_csv(\"pdb_chain_table.csv\")\n",
    "input_df[\"PDB_ID\"] = input_df[\"PDB_ID\"].str.lower()\n",
    "codes_list = input_df[[\"PDB_ID\"]].drop_duplicates().PDB_ID.tolist()\n",
    "df_dict = {}\n",
    "for pdb_id in codes_list:\n",
    "    %run PDBrenum.py -rfla {pdb_id}\n",
    "    df = pd.read_fwf(\"log_corrected.txt\", )\n",
    "    print(df)\n",
    "    dfsub = df[['PDB_id', 'chain_PDB','UniProt']]\n",
    "    df_dict_single = dfsub.groupby('PDB_id').apply(lambda x: dict(zip(x.chain_PDB, x.UniProt))).to_dict()\n",
    "    print(df_dict_single)\n",
    "    try: # this `try/except` clause will allow for bad PDB id codes by skipping trying to add them since fails when empty\n",
    "        df_dict[pdb_id] = df_dict_single[pdb_id]\n",
    "    except KeyError:\n",
    "        pass\n",
    "def lookup_id(items):\n",
    "    '''\n",
    "    takes a row with PDB_ID and CHAIN_ID and returns corresponding UniProt ID\n",
    "    '''\n",
    "    pdb_id = items[0].lower()\n",
    "    chain_id = items[1] \n",
    "    if pdb_id not in df_dict:\n",
    "        return 'NA'\n",
    "    if chain_id not in df_dict[pdb_id]:\n",
    "        return 'NA'\n",
    "    uniprot_id = df_dict[pdb_id][chain_id]\n",
    "    return uniprot_id\n",
    "result_each_code_df = input_df.copy()\n",
    "result_each_code_df['UniProt'] = result_each_code_df.apply(lookup_id, axis=1)\n",
    "result_each_code_df.to_csv(\"one_at_a_time_result_with_uniprot.tsv\",index=False, sep = \"\\t\")\n",
    "result_each_code_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'7dpa': {'A': 'Q9H7D0',\n",
       "  'B': 'P63000',\n",
       "  'C': 'Q92556',\n",
       "  'D': 'Q9H7D0',\n",
       "  'E': 'P63000',\n",
       "  'F': 'Q92556'},\n",
       " '1bzq': {'A': 'P61823', 'B': 'P61823', 'C': 'P61823', 'D': 'P61823'}}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDB_ID\tCHAIN_ID\tUniProt\n",
      "7dpa\tA\tQ9H7D0\n",
      "xxxx\tX\tNA\n",
      "7dpa\tB\tP63000\n",
      "7dpa\tZ\tNA\n",
      "1bzq\tA\tP61823\n",
      "7dpa\tz\tNA\n",
      "1bzq\tA\tP61823\n",
      "1bzq\ta\tNA\n",
      "1bzq\ta\tNA\n"
     ]
    }
   ],
   "source": [
    "!cat one_at_a_time_result_with_uniprot.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same results; however, the larger area highligthed in pink which is coming from the numerous uses of PDBrenum starts to give a sense already this is a less effficient route. However, it's only slightly less and accepting some inefficiency of this step alone may not add much time at all and allow more easily adapting the code to the workflow you need."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B: Using a list of PDB codes and iterating on each PDB id code running PDBrenum one at time\n",
    "\n",
    "Section 'B: Using a list of PDB codes' above covered two ways to read in the list of PDB id codes. We'll just use Pandas to read in here. If you want to use basic Python, you can see how the code in that section was adapted and adapt the version here.\n",
    "\n",
    "Using the first example in Section 'B: Using a list of PDB codes', above, we'll adapt in iterating on the individual PDB code ids and running PDBrenum for each. That produces data for each that we'll read into a dataframe for each as we iterate and them combine all those to produce one for all the input PDBs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading mmCIF files: 100%|██████████| 1/1 [00:00<00:00,  2.17it/s]\n",
      "Downloading SIFTS files: 100%|██████████| 1/1 [00:00<00:00,  1.75it/s]\n",
      "Renumbering mmCIF files: 100%|██████████| 1/1 [00:02<00:00,  2.82s/it]\n",
      "Checking mmCIF files: 100%|██████████| 3/3 [00:01<00:00,  2.91it/s]\n",
      "Renumbering mmCIF files: 100%|██████████| 1/1 [00:02<00:00,  2.76s/it]\n",
      "Checking mmCIF files: 100%|██████████| 2/2 [00:01<00:00,  1.99it/s]\n",
      "Downloading mmCIF files: 100%|██████████| 1/1 [00:00<00:00,  7.04it/s]\n",
      "Downloading mmCIF files: 100%|██████████| 1/1 [00:00<00:00,  9.05it/s]\n",
      "Downloading mmCIF files: 100%|██████████| 1/1 [00:00<00:00,  9.38it/s]\n",
      "Downloading SIFTS files: 100%|██████████| 1/1 [00:00<00:00,  4.68it/s]\n",
      "Downloading SIFTS files: 100%|██████████| 1/1 [00:00<00:00,  4.48it/s]\n",
      "Downloading SIFTS files: 100%|██████████| 1/1 [00:00<00:00,  4.69it/s]\n",
      "Renumbering mmCIF files: 0it [00:00, ?it/s]\n",
      "Checking mmCIF files: 100%|██████████| 2/2 [00:00<00:00,  2.06it/s]\n",
      "Downloading mmCIF files: 100%|██████████| 1/1 [00:00<00:00,  2.24it/s]\n",
      "Downloading SIFTS files: 100%|██████████| 1/1 [00:00<00:00,  2.43it/s]\n",
      "Renumbering mmCIF files: 100%|██████████| 1/1 [00:02<00:00,  2.15s/it]\n",
      "Checking mmCIF files: 100%|██████████| 2/2 [00:00<00:00,  2.09it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PDB_id</th>\n",
       "      <th>chain_PDB</th>\n",
       "      <th>UniProt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>7dpa</td>\n",
       "      <td>A</td>\n",
       "      <td>Q9H7D0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>7dpa</td>\n",
       "      <td>B</td>\n",
       "      <td>P63000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>7dpa</td>\n",
       "      <td>C</td>\n",
       "      <td>Q92556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>7dpa</td>\n",
       "      <td>D</td>\n",
       "      <td>Q9H7D0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>7dpa</td>\n",
       "      <td>E</td>\n",
       "      <td>P63000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>7dpa</td>\n",
       "      <td>F</td>\n",
       "      <td>Q92556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1bzq</td>\n",
       "      <td>A</td>\n",
       "      <td>P61823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1bzq</td>\n",
       "      <td>B</td>\n",
       "      <td>P61823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1bzq</td>\n",
       "      <td>C</td>\n",
       "      <td>P61823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1bzq</td>\n",
       "      <td>D</td>\n",
       "      <td>P61823</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PDB_id chain_PDB UniProt\n",
       "0   7dpa         A  Q9H7D0\n",
       "1   7dpa         B  P63000\n",
       "2   7dpa         C  Q92556\n",
       "3   7dpa         D  Q9H7D0\n",
       "4   7dpa         E  P63000\n",
       "5   7dpa         F  Q92556\n",
       "6   1bzq         A  P61823\n",
       "7   1bzq         B  P61823\n",
       "8   1bzq         C  P61823\n",
       "9   1bzq         D  P61823"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_simple = pd.read_csv('codes.txt', header=None, names = ['PDB_ids'])\n",
    "codes_list = df_simple['PDB_ids'].to_list()\n",
    "dfs_collected = []\n",
    "df_dict = {} # this will only be used here for screening bad PDB id codes that make empty dataframes\n",
    "for pdb_id in codes_list:\n",
    "    %run PDBrenum.py -rfla {pdb_id}\n",
    "    df = pd.read_fwf(\"log_corrected.txt\", )\n",
    "    dfsub = df[['PDB_id', 'chain_PDB','UniProt']]\n",
    "    df_dict_single = dfsub.groupby('PDB_id').apply(lambda x: dict(zip(x.chain_PDB, x.UniProt))).to_dict()\n",
    "    try: # this `try/except` will allow for bad PDB id codes by skipping trying to add anything concerning them since dictionary lookup fails when empty\n",
    "        df_dict[pdb_id] = df_dict_single[pdb_id]\n",
    "        dfs_collected.append(dfsub)\n",
    "    except KeyError:\n",
    "        pass\n",
    "df_results = pd.concat(dfs_collected, ignore_index= True)\n",
    "df_results.to_csv(\"all_result_with_uniprot.tsv\",index=False, sep = \"\\t\")\n",
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes on Snakemake and PDBrenum to mapping chain IDs to UniProt IDs\n",
    "---------------\n",
    "\n",
    "If you are familiar with any of my other scripts and workflows, you may know I like snakemake for pulling things together into a useable pipeline. So why not here? It certainly could be done. One of the main benefits of snakemake is that upon change in files, say adding input, it will analyze your pipeline for any product it doesn't have have and make just that product. However, to get that benefit here in conjunction with PDBrenum use, it would necessitate handling a lot of steps that aren't already there. Frankly, PDBrenum is set up to be a pipeline in itself. The steps needed to process a lot pod PDB files are straightforward and easy to write/adapt. It seems making it a snakemake wokflow at this time isn't worth the effort."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------\n",
    "\n",
    "Enjoy!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "----\n",
    "\n",
    "----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
